{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd063dd-8488-4491-8ca3-ae2c1fe179e2",
   "metadata": {},
   "source": [
    "# Companies House Public Data API Project Using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4aebcc9-19b3-4b70-93dc-895d5a84d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for making HTTP requests to the Companies House API\n",
    "import requests\n",
    "# for working with JASON data (parsing API responses, encoding addresses)\n",
    "import json\n",
    "# for adding delays between API called to avoid rate limiting\n",
    "import time\n",
    "# for writing data to a csv file in a structured format\n",
    "import csv\n",
    "# for interacting with the operating system (managing file paths or environment variables)\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95deffe6-626e-4770-a6fa-2078d8a203aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(filepath=\"config.txt\"):\n",
    "    \"\"\"\n",
    "    Load an API Key from a config file.\n",
    "    The file must contain a line likeL API_KEY=your-key-here\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"API_KEY=\"):\n",
    "                return line.strip().split(\"=\")[1]\n",
    "    raise ValueError(\"API_KEY not found in config file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96140eaf-e813-4930-b0cd-c1820d1e68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key from config file - this avoids hardcoding the key into the script\n",
    "API_KEY = load_api_key()\n",
    "# set the base URL for all API calls\n",
    "BASE_URL = \"https://api.company-information.service.gov.uk\"\n",
    "# specify that the client expects JSON responses from the API\n",
    "HEADERS = {\"Accept\": \"application/json\"}\n",
    "# file name where all fetched company profile data will be saved as a CSV\n",
    "OUTPUT_FILE = \"company_profiles.csv\"\n",
    "# time delay (in seconds) between consecutive API requests to avoid hitting rate limits\n",
    "DELAY_BETWEEN_REQUESTS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbf6fa39-da42-42df-bfe8-eb3265aff1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ftse100_from_lse(headless=True, save_to_csv=False):\n",
    "    url = \"https://www.londonstockexchange.com/indices/ftse-100/constituents/table\"\n",
    "\n",
    "    # Setup ChromeDriver\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    companies = []\n",
    "\n",
    "    print(\"Loading FTSE 100 companies from all pages...\")\n",
    "\n",
    "    for page in range(5):  # 5 pages, 20 companies each\n",
    "        # Wait for table to be present\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table tbody tr\")))\n",
    "        time.sleep(2)  # slight buffer\n",
    "\n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, \"table tbody tr\")\n",
    "        for row in rows:\n",
    "            try:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                name = cells[0].text.strip()\n",
    "                ticker = cells[1].text.strip()\n",
    "                companies.append((name, ticker))\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipped row: {e}\")\n",
    "\n",
    "        # try clicking the \"Next\" pagination button if not on last page\n",
    "        if page < 4:\n",
    "            try:\n",
    "                next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.pagination__btn--next\")))\n",
    "                next_button.click()\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed to click 'Next' on page {page+1}: {e}\")\n",
    "                break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    if save_to_csv:\n",
    "        pd.DataFrame(companies, columns=[\"Company\", \"Ticker\"]).to_csv(\"ftse100_lse.csv\", index=False)\n",
    "        print(\"Saved all FTSE 100 companies to ftse100_lse.csv\")\n",
    "\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7678fb-8985-4711-bd35-b17efda9e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ftse_companies = get_ftse100_from_lse(save_to_csv=True)\n",
    "    print(f\"Retrieved {len(ftse_companies)} FTSE 100 companies.\")\n",
    "    for name, ticker in ftse_companies[:40]:\n",
    "        print(f\"- {name} ({ticker})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6469c898-dfb3-45ac-858c-a7e1ed42e1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c63b952-5cb0-4771-ac69-d3fbc15fc399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetches the core company profile from the Companies House API\n",
    "def fetch_company_profile(company_number):\n",
    "    # construct the API URL for the company's main profile\n",
    "    url = f\"{BASE_URL}/company/{company_number}\"\n",
    "    try:\n",
    "        # send GET request with basic auth (API key only)\n",
    "        response = requests.get(url, auth=(API_KEY, \"\"), headers=HEADERS)\n",
    "        if response.status_code == 200:\n",
    "            # return JSON data if successful\n",
    "            return response.json()\n",
    "        else:\n",
    "            # log status code if note successful\n",
    "            print(f\"[{response.status_code}] Failed to fetch {company_number}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # catch and log connection or parsing errors\n",
    "        print(f\"[ERROR] {company_number}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# retrieves a list of up to 3 officer (director) names for the company\n",
    "def fetch_officers(company_number):\n",
    "    url = f\"{BASE_URL}/company/{company_number}/officers\"\n",
    "    response = requests.get(url, auth=(API_KEY, \"\"), headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # limit to first 3 officers\n",
    "        officers = data.get(\"items\", [])[:3]\n",
    "        # return only officer names, filtering out any nulls\n",
    "        return [str(o.get(\"name\", \"Unknown\")) for o in officers if o.get(\"name\")]\n",
    "    # return empty list if request fails or no officers\n",
    "    return []\n",
    "\n",
    "# retrieves up to 5 most recent filing history entries\n",
    "def fetch_filing_history(company_number):\n",
    "    url = f\"{BASE_URL}/company/{company_number}/filing-history\"\n",
    "    response = requests.get(url, auth=(API_KEY, \"\"), headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # limit to 5 filings\n",
    "        filings = data.get(\"items\", [])[:5]\n",
    "        # format: \"filing_type on date\"\n",
    "        return [f\"{str(f.get('type', 'UNKNOWN'))} on {str(f.get('date', 'UNKNOWN'))}\" for f in filings]\n",
    "    return []\n",
    "\n",
    "# retrieves up to 3 charge entries (e.g. mortgage or secured lending)\n",
    "def fetch_charges(company_number):\n",
    "    url = f\"{BASE_URL}/company/{company_number}/charges\"\n",
    "    response = requests.get(url, auth=(API_KEY, \"\"), headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # limits to 3 charges\n",
    "        charges = data.get(\"items\", [])[:3]\n",
    "        # get charge codes, safely convert to string\n",
    "        return [str(c.get(\"charge_code\", \"Unknown\")) for c in charges if c.get(\"charge_code\")]\n",
    "    return []\n",
    "\n",
    "# retrieves up to 3 names of Persons with Significant Control (PSC)\n",
    "def fetch_psc(company_number):\n",
    "    url = f\"{BASE_URL}/company/{company_number}/persons-with-significant-control\"\n",
    "    response = requests.get(url, auth=(API_KEY, \"\"), headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # limit to 3 PSC entries\n",
    "        pscs = data.get(\"items\", [])[:3]\n",
    "        # return PSC names if present\n",
    "        return [str(p.get(\"name\", \"Unknown\")) for p in pscs if p.get(\"name\")]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b5abd9b-6688-4bec-8ba0-6e72c7df2b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 20 companies...\n",
      "Saved 1 company profiles to company_profiles.csv\n",
      "Saved 2 company profiles to company_profiles.csv\n",
      "Saved 3 company profiles to company_profiles.csv\n",
      "Saved 4 company profiles to company_profiles.csv\n",
      "Saved 5 company profiles to company_profiles.csv\n",
      "Saved 6 company profiles to company_profiles.csv\n",
      "Saved 7 company profiles to company_profiles.csv\n",
      "Saved 8 company profiles to company_profiles.csv\n",
      "Saved 9 company profiles to company_profiles.csv\n",
      "Saved 10 company profiles to company_profiles.csv\n",
      "Saved 11 company profiles to company_profiles.csv\n",
      "Saved 12 company profiles to company_profiles.csv\n",
      "Saved 13 company profiles to company_profiles.csv\n",
      "Saved 14 company profiles to company_profiles.csv\n",
      "Saved 15 company profiles to company_profiles.csv\n",
      "Saved 16 company profiles to company_profiles.csv\n",
      "Saved 17 company profiles to company_profiles.csv\n",
      "Saved 18 company profiles to company_profiles.csv\n",
      "Saved 19 company profiles to company_profiles.csv\n",
      "Saved 20 company profiles to company_profiles.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # print the number of companies to be processed\n",
    "    print(f\"Fetching data for {len(COMPANY_NUMBERS)} companies...\")\n",
    "\n",
    "    # initialise an empty list to collect all results (one dict per company)\n",
    "    results = []\n",
    "\n",
    "    # loop over each company number in the list\n",
    "    for number in COMPANY_NUMBERS:\n",
    "        # fetch the company's profile (core metadata)\n",
    "        data = fetch_company_profile(number)\n",
    "\n",
    "        # if data was successfully retrieved, enrich and store it\n",
    "        if data:\n",
    "            results.append({\n",
    "                # extract basic company information from the profile\n",
    "                \"company_number\": data.get(\"company_number\"),\n",
    "                \"company_name\": data.get(\"company_name\"),\n",
    "                \"status\": data.get(\"company_status\"),\n",
    "                \"date_of_creation\": data.get(\"date_of_creation\"),\n",
    "                \"type\": data.get(\"type\"),\n",
    "                \"company_category\": data.get(\"company_category\"),\n",
    "                \"jurisdiction\": data.get(\"jurisdiction\"),\n",
    "\n",
    "                # financial reporting data\n",
    "                \"last_accounts_date\": data.get(\"accounts\", {}).get(\"last_accounts\", {}).get(\"made_up_to\"),\n",
    "                \"next_accounts_due\": data.get(\"accounts\", {}).get(\"next_due\"),\n",
    "\n",
    "                # latest confirmation statement date\n",
    "                \"confirmation_statement_date\": data.get(\"confirmation_statement\", {}).get(\"last_made_up_to\"),\n",
    "\n",
    "                # whether the company has a history of insolvency\n",
    "                \"has_insolvency_history\": data.get(\"has_insolvency_history\"),\n",
    "\n",
    "                # flatten the address JSON structure into a string\n",
    "                \"registered_office_address\": json.dumps(data.get(\"registered_office_address\", {})),\n",
    "\n",
    "                # list of SIC (Standard Industrial Classification) codes, joined into one string\n",
    "                \"sic_codes\": \",\".join(data.get(\"sic_codes\", [])),\n",
    "\n",
    "                # enriched data from additional endpoints\n",
    "                \"officers\": \"; \".join(fetch_officers(number)), # top 3 officers\n",
    "                \"recent_filings\": \"; \".join(fetch_filing_history(number)), # latest 5 filings\n",
    "                \"charges\": \"; \".join(fetch_charges(number)), # top 3 charge codes\n",
    "                \"psc\": \"; \".join(fetch_psc(number)) # up to 3 persons with significant control\n",
    "            })\n",
    "\n",
    "        # wait between requests to avoid hitting rate limits\n",
    "        time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "        # save the current state of the results to CSV after each company\n",
    "        keys = results[0].keys() if results else [] # get column headers from first result\n",
    "        with open(OUTPUT_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "\n",
    "        # log the progress\n",
    "        print(f\"Saved {len(results)} company profiles to {OUTPUT_FILE}\")\n",
    "\n",
    "# entry point of the script - only runs when file is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3b64b-dd8d-4a2a-b648-ef15e1eaf824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
